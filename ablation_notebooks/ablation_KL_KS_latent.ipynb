{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation study on KS dataset for PFNN latent dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from model.utilities import *\n",
    "from model.vae_base import *\n",
    "import sys\n",
    "sys.path.append('./model')\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy.random as random\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "font = {'size'   : 12, 'family': 'Times New Roman'}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3678717/605233945.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_tensor = torch.tensor(data_raw, dtype=torch.float)[...,::sub]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Main\n",
    "n_train = 900\n",
    "n_test = 100\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "sub = 4 # spatial subsample\n",
    "S = 512\n",
    "s = S//sub\n",
    "\n",
    "T_in = 500 # skip first 100 seconds of each trajectory to let trajectory reach attractor\n",
    "T = 1100 # seconds to extract from each trajectory in data\n",
    "T_out = T_in + T\n",
    "step = 1 # Seconds to learn solution operator\n",
    "\n",
    "# Load data\n",
    "predloader = MatReader('./data/KS.mat') # load the generated data\n",
    "data_raw = predloader.read_field('u')\n",
    "data_tensor = torch.tensor(data_raw, dtype=torch.float)[...,::sub]\n",
    "\n",
    "# randomly sample half episodes from the train data episodes\n",
    "episode_samples = int(0.5*n_train)\n",
    "data_sampled_train = data_tensor[torch.randperm(data_tensor[:n_train].size(0))[:episode_samples],:,:]\n",
    "# data_sampled_test = data_tensor[torch.randperm(data_tensor[-n_test:].size(0)),:,:]\n",
    "data_test = data_tensor[-n_test:,:,:]\n",
    "\n",
    "train_sample = data_sampled_train[:,T_in:T_out,:].reshape(-1, s)\n",
    "test_a = data_test[:,T_in-1:T_out-1,:].reshape(-1, s)\n",
    "test_u = data_test[:,T_in:T_out,:].reshape(-1, s)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "PFNN_latent_1_path = 'fill_PFNN_latent_128_model_path'\n",
    "model_latent_1 = torch.load(PFNN_latent_1_path, map_location=device)\n",
    "\n",
    "PFNN_latent_2_path = 'fill_PFNN_latent_256_model_path'\n",
    "model_latent_2 = torch.load(PFNN_latent_2_path, map_location=device)\n",
    "\n",
    "PFNN_latent_4_path = 'fill_PFNN_latent_512_model_path'\n",
    "model_latent_4 = torch.load(PFNN_latent_4_path, map_location=device)\n",
    "\n",
    "PFNN_latent_8_path = 'fill_PFNN_latent_1024_model_path'\n",
    "model_latent_8 = torch.load(PFNN_latent_8_path, map_location=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_prediction(model, test_a, id, steps_per_sec, out_dim, in_dim, koopman = False, ae=False, T=T):\n",
    "      model.eval()\n",
    "      # id = id*T\n",
    "      test_a_0 = test_a[id]\n",
    "\n",
    "      pred = torch.zeros(T, out_dim)\n",
    "      out = test_a_0.reshape(1,in_dim).to(device)\n",
    "      with torch.no_grad():\n",
    "            for i in range(T):\n",
    "                  if koopman:\n",
    "                        out = model(out, mode='forward')[0][0]\n",
    "                  elif ae:\n",
    "                        out = model(out.reshape(1,in_dim))[0]\n",
    "                  else:\n",
    "                        out = model(out.reshape(1,in_dim,1))\n",
    "                  pred[i] = out.view(out_dim,)\n",
    "      \n",
    "      return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: torch.Size([110000, 128])\n",
      "Reduced shape: (110000, 5)\n",
      "Number of components selected: 5\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Instantiate PCA object\n",
    "# To keep all components but see how many are needed for 95% variance, you can set n_components to 0.95\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "# Step 2: Fit PCA on the data\n",
    "pca.fit(np.concatenate((train_sample, test_u), axis=0))\n",
    "\n",
    "# Step 3: Transform the data to get the principal components\n",
    "test_u_pca = pca.transform(test_u)\n",
    "\n",
    "# The transformed data `test_u_pca` now has fewer dimensions, with 95% of the original variance retained\n",
    "print(\"Original shape:\", test_u.shape)\n",
    "print(\"Reduced shape:\", test_u_pca.shape)\n",
    "\n",
    "# If you want to see the number of components selected\n",
    "print(\"Number of components selected:\", pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_model1_long_pred = []\n",
    "reduced_model2_long_pred = []\n",
    "reduced_model3_long_pred = []\n",
    "reduced_model4_long_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "      for init_id in range(n_test):\n",
    "            latent_1_long_pred = long_prediction(model_latent_1, test_a, init_id*T, 1, s, s, ae=True)\n",
    "            latent_2_long_pred = long_prediction(model_latent_2, test_a, init_id*T, 2, s, s, ae=True)\n",
    "            latent_4_long_pred = long_prediction(model_latent_4, test_a, init_id*T, 4, s, s, ae=True)\n",
    "            latent_8_long_pred = long_prediction(model_latent_8, test_a, init_id*T, 8, s, s, ae=True)\n",
    "\n",
    "\n",
    "            reduced_model1_long_pred.append(pca.transform(latent_1_long_pred))\n",
    "            reduced_model2_long_pred.append(pca.transform(latent_2_long_pred))\n",
    "            reduced_model3_long_pred.append(pca.transform(latent_4_long_pred))\n",
    "            reduced_model4_long_pred.append(pca.transform(latent_8_long_pred))\n",
    "\n",
    "\n",
    "reduced_model1_long_pred = np.concatenate(reduced_model1_long_pred, axis=0)\n",
    "reduced_model2_long_pred = np.concatenate(reduced_model2_long_pred, axis=0)\n",
    "reduced_model3_long_pred = np.concatenate(reduced_model3_long_pred, axis=0)\n",
    "reduced_model4_long_pred = np.concatenate(reduced_model4_long_pred, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate KL divergence of principle compoennets' distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_truth_pca = calculate_kde(pca.transform(np.concatenate([train_sample, test_u])))\n",
    "kde_latent_1_pca = calculate_kde(reduced_model1_long_pred)\n",
    "kde_latent_2_pca = calculate_kde(reduced_model2_long_pred)\n",
    "kde_latent_4_pca = calculate_kde(reduced_model3_long_pred)\n",
    "kde_latent_8_pca = calculate_kde(reduced_model4_long_pred)\n",
    "x_range = np.linspace(np.concatenate([train_sample, test_u]).min()-5, np.concatenate([train_sample, test_u]).max()+5, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension 1\n",
      "p_x: [0.00076578 0.00076647 0.00076716 ... 0.0009838  0.0009832  0.0009826 ] p_x shape: 40000\n",
      "q_x: [0.00011974 0.00012005 0.00012035 ... 0.00125472 0.00125447 0.00125422] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_1: 83.4974924409619\n",
      "p_x: [0.00076578 0.00076647 0.00076716 ... 0.0009838  0.0009832  0.0009826 ] p_x shape: 40000\n",
      "q_x: [0.00026265 0.00026304 0.00026342 ... 0.00033662 0.00033624 0.00033586] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_2: 28.03252220172805\n",
      "p_x: [0.00076578 0.00076647 0.00076716 ... 0.0009838  0.0009832  0.0009826 ] p_x shape: 40000\n",
      "q_x: [0.00066794 0.00066803 0.00066812 ... 0.00021954 0.00021935 0.00021916] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_4: 4.281563488371166\n",
      "p_x: [0.00076578 0.00076647 0.00076716 ... 0.0009838  0.0009832  0.0009826 ] p_x shape: 40000\n",
      "q_x: [0.0132704  0.01327096 0.01327153 ... 0.06419277 0.06418683 0.06418089] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_8: 1855.2273992925175\n",
      "Dimension 2\n",
      "p_x: [0.00071302 0.00071344 0.00071386 ... 0.00077646 0.00077587 0.00077527] p_x shape: 40000\n",
      "q_x: [0.00016325 0.00016337 0.0001635  ... 0.00046467 0.00046438 0.0004641 ] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_1: 25.62043714246936\n",
      "p_x: [0.00071302 0.00071344 0.00071386 ... 0.00077646 0.00077587 0.00077527] p_x shape: 40000\n",
      "q_x: [0.0004909  0.00049136 0.00049182 ... 0.00175369 0.0017527  0.00175171] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_2: 84.85506674698058\n",
      "p_x: [0.00071302 0.00071344 0.00071386 ... 0.00077646 0.00077587 0.00077527] p_x shape: 40000\n",
      "q_x: [0.00042684 0.00042711 0.00042739 ... 0.00044746 0.00044723 0.000447  ] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_4: 2.9043166053834693\n",
      "p_x: [0.00071302 0.00071344 0.00071386 ... 0.00077646 0.00077587 0.00077527] p_x shape: 40000\n",
      "q_x: [0.02221798 0.02221966 0.02222134 ... 0.02401059 0.02401011 0.02400964] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_8: 1489.0873789801078\n",
      "Dimension 3\n",
      "p_x: [0.00079657 0.00079712 0.00079767 ... 0.00080196 0.00080164 0.00080132] p_x shape: 40000\n",
      "q_x: [0.00021274 0.00021287 0.000213   ... 0.00019779 0.00019783 0.00019787] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_1: 45.76357007661318\n",
      "p_x: [0.00079657 0.00079712 0.00079767 ... 0.00080196 0.00080164 0.00080132] p_x shape: 40000\n",
      "q_x: [1.94085238e-05 1.94870476e-05 1.95658377e-05 ... 1.33476633e-03\n",
      " 1.33456477e-03 1.33436251e-03] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_2: 61.186879596292314\n",
      "p_x: [0.00079657 0.00079712 0.00079767 ... 0.00080196 0.00080164 0.00080132] p_x shape: 40000\n",
      "q_x: [0.00056375 0.00056402 0.0005643  ... 0.00032868 0.0003285  0.00032832] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_4: 12.710760620947614\n",
      "p_x: [0.00079657 0.00079712 0.00079767 ... 0.00080196 0.00080164 0.00080132] p_x shape: 40000\n",
      "q_x: [0.01222767 0.01222875 0.01222983 ... 0.03311349 0.03311189 0.03311029] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_8: 930.8487443012264\n",
      "Dimension 4\n",
      "p_x: [0.00034521 0.00034557 0.00034593 ... 0.00040278 0.00040248 0.00040219] p_x shape: 40000\n",
      "q_x: [3.97241118e-04 3.97608835e-04 3.97976769e-04 ... 3.65993276e-07\n",
      " 3.63764747e-07 3.61548692e-07] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_1: 38.10957748182999\n",
      "p_x: [0.00034521 0.00034557 0.00034593 ... 0.00040278 0.00040248 0.00040219] p_x shape: 40000\n",
      "q_x: [3.09319179e-04 3.09569257e-04 3.09819436e-04 ... 1.98481106e-06\n",
      " 1.97455057e-06 1.96433760e-06] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_2: 27.158333212506605\n",
      "p_x: [0.00034521 0.00034557 0.00034593 ... 0.00040278 0.00040248 0.00040219] p_x shape: 40000\n",
      "q_x: [0.00039789 0.00039808 0.00039827 ... 0.00062449 0.0006237  0.00062292] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_4: 3.7193841917891337\n",
      "p_x: [0.00034521 0.00034557 0.00034593 ... 0.00040278 0.00040248 0.00040219] p_x shape: 40000\n",
      "q_x: [0.01741309 0.01741298 0.01741288 ... 0.01383651 0.01383615 0.01383579] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_8: 2861.4270398088706\n",
      "Dimension 5\n",
      "p_x: [0.00039387 0.00039411 0.00039435 ... 0.00038846 0.00038819 0.00038793] p_x shape: 40000\n",
      "q_x: [2.88255563e-04 2.88783869e-04 2.89312678e-04 ... 2.73541659e-05\n",
      " 2.72570663e-05 2.71602337e-05] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_1: 57.602198922806046\n",
      "p_x: [0.00039387 0.00039411 0.00039435 ... 0.00038846 0.00038819 0.00038793] p_x shape: 40000\n",
      "q_x: [0.00051439 0.0005147  0.00051501 ... 0.00047485 0.00047448 0.00047411] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_2: 5.429278700912094\n",
      "p_x: [0.00039387 0.00039411 0.00039435 ... 0.00038846 0.00038819 0.00038793] p_x shape: 40000\n",
      "q_x: [7.04691288e-07 7.08888312e-07 7.13108564e-07 ... 5.29944071e-04\n",
      " 5.29212904e-04 5.28482620e-04] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_4: 9.175811434375271\n",
      "p_x: [0.00039387 0.00039411 0.00039435 ... 0.00038846 0.00038819 0.00038793] p_x shape: 40000\n",
      "q_x: [0.02360399 0.02360632 0.02360864 ... 0.01580798 0.01580636 0.01580474] q_x shape: 40000\n",
      "KL divergence (PC distribution) True vs latent_8: 1050.704077139209\n"
     ]
    }
   ],
   "source": [
    "kl_dim_tru_latent_1 = []\n",
    "kl_dim_tru_latent_2 = []\n",
    "kl_dim_tru_latent_4 = []\n",
    "kl_dim_tru_latent_8 = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "      print(f\"Dimension {i+1}\")\n",
    "\n",
    "      kl_dim_tru_latent_1_i = kl_divergence(kde_truth_pca[i], kde_latent_1_pca[i], x_range)\n",
    "      kl_dim_tru_latent_1.append(kl_dim_tru_latent_1_i)\n",
    "      print(f\"KL divergence (PC distribution) True vs latent_1*128: {kl_dim_tru_latent_1_i}\")\n",
    "\n",
    "      kl_dim_tru_latent_2_i = kl_divergence(kde_truth_pca[i], kde_latent_2_pca[i], x_range)\n",
    "      kl_dim_tru_latent_2.append(kl_dim_tru_latent_2_i)\n",
    "      print(f\"KL divergence (PC distribution) True vs latent_2*128: {kl_dim_tru_latent_2_i}\")\n",
    "\n",
    "      kl_dim_tru_latent_4_i = kl_divergence(kde_truth_pca[i], kde_latent_4_pca[i], x_range)\n",
    "      kl_dim_tru_latent_4.append(kl_dim_tru_latent_4_i)\n",
    "      print(f\"KL divergence (PC distribution) True vs latent_4*128: {kl_dim_tru_latent_4_i}\")\n",
    "\n",
    "      kl_dim_tru_latent_8_i = kl_divergence(kde_truth_pca[i], kde_latent_8_pca[i], x_range)\n",
    "      kl_dim_tru_latent_8.append(kl_dim_tru_latent_8_i)\n",
    "      print(f\"KL divergence (PC distribution) True vs latent_8*128: {kl_dim_tru_latent_8_i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_operator_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
