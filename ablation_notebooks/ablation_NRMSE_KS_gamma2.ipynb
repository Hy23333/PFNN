{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation study on KS dataset for PFNN consist on short-term predictions after contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.utilities import *\n",
    "from model.koopman_base import *\n",
    "# from models.fno_1d import *\n",
    "import sys\n",
    "sys.path.append('./models')\n",
    "\n",
    "import numpy.random as random\n",
    "\n",
    "font = {'size'   : 12, 'family': 'Times New Roman'}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r1/v7355v5n0y3cw6l975b_dspm0000gn/T/ipykernel_43559/1272648692.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_tensor = torch.tensor(data_raw, dtype=torch.float)[...,::sub]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Main\n",
    "n_train = 1000\n",
    "n_test = 100\n",
    "\n",
    "sub = 4 # spatial subsample\n",
    "S = 512\n",
    "s = S//sub\n",
    "\n",
    "T_in = 500 # skip first 500 seconds of each trajectory to keep trajectory on attractor\n",
    "T = 200 # seconds to extract from each trajectory in data\n",
    "T_out = T_in + T\n",
    "step = 1 # Seconds to learn solution operator\n",
    "\n",
    "# Load data\n",
    "predloader = MatReader('./data/KS.mat') # load the generated data\n",
    "data_raw = predloader.read_field('u')\n",
    "data_tensor = torch.tensor(data_raw, dtype=torch.float)[...,::sub]\n",
    "data_test = data_tensor[-n_test:,:,:]\n",
    "\n",
    "test_a = data_test[:,T_in-1:T_out-1,:].reshape(-1, s)\n",
    "test_u = data_test[:,T_in:T_out,:].reshape(-1, s)\n",
    "batch_size = 100\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "PFNN_consist_0_path = 'fill_PFNN_gamma2_0_model_path'\n",
    "model_consist_0 = torch.load(PFNN_consist_0_path, map_location=device)\n",
    "\n",
    "PFNN_consist_01_path = 'fill_PFNN_gamma2_01_model_path'\n",
    "model_consist_01 = torch.load(PFNN_consist_01_path, map_location=device)\n",
    "\n",
    "PFNN_consist_03_path = 'fill_PFNN_gamma2_03_model_path'\n",
    "model_consist_03 = torch.load(PFNN_consist_03_path, map_location=device)\n",
    "\n",
    "PFNN_consist_05_path = 'fill_PFNN_gamma2_05_model_path'\n",
    "model_consist_05 = torch.load(PFNN_consist_05_path, map_location=device)\n",
    "\n",
    "PFNN_consist_1_path = 'fill_PFNN_gamma2_1_model_path'\n",
    "model_consist_1 = torch.load(PFNN_consist_1_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_l2_loss(pred, truth, n = 100):\n",
    "    return torch.mean((pred[:n] - truth[:n])**2)\n",
    "\n",
    "def episode_loss_collection(regressive_steps, loss_fn, test_u, pred_1, pred_2, pred_3, pred_4, pred_5):\n",
    "      loss_dict = {}\n",
    "\n",
    "      loss_consist_0 = loss_fn(pred_1, test_u, n=regressive_steps)\n",
    "      loss_consist_01 = loss_fn(pred_2, test_u, n=regressive_steps)\n",
    "      loss_consist_03 = loss_fn(pred_3, test_u, n=regressive_steps)\n",
    "      loss_consist_05 = loss_fn(pred_4, test_u, n=regressive_steps)\n",
    "      loss_consist_1 = loss_fn(pred_5, test_u, n=regressive_steps)\n",
    "            \n",
    "      loss_dict['consist_0'] = loss_consist_0.item()\n",
    "      loss_dict['consist_01'] = loss_consist_01.item()\n",
    "      loss_dict['consist_03'] = loss_consist_03.item()\n",
    "      loss_dict['consist_05'] = loss_consist_05.item()\n",
    "      loss_dict['consist_1'] = loss_consist_1.item()\n",
    "\n",
    "      return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_n: 100 started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.13it/s]\n"
     ]
    }
   ],
   "source": [
    "steps_n_list = np.array([100])\n",
    "error_df_list = {}\n",
    "for steps_n in steps_n_list:\n",
    "      print('steps_n:', steps_n, 'started.')\n",
    "      error_df = pd.DataFrame(columns=['consist_0', 'consist_01', 'consist_03', 'consist_05', 'consist_1'])\n",
    "      # for init_id in range(test_samples):\n",
    "      for init_id in tqdm(np.arange(n_test)):\n",
    "            consist_0_long_pred = long_prediction(model_consist_0, test_a, init_id, 1, s, s, T=steps_n)\n",
    "            consist_01_long_pred = long_prediction(model_consist_01, test_a, init_id, 1, s, s, T=steps_n)\n",
    "            consist_03_long_pred = long_prediction(model_consist_03, test_a, init_id, 1, s, s, T=steps_n)\n",
    "            consist_05_long_pred = long_prediction(model_consist_05, test_a, init_id, 1, s, s, T=steps_n)\n",
    "            consist_1_long_pred = long_prediction(model_consist_1, test_a, init_id, 1, s, s, T=steps_n)\n",
    "\n",
    "            episode_loss_dict = episode_loss_collection(steps_n, episode_l2_loss, test_u[int(init_id*T):], consist_0_long_pred, consist_01_long_pred, consist_03_long_pred, consist_05_long_pred, consist_1_long_pred)\n",
    "            error_df.loc[init_id] = episode_loss_dict\n",
    "      error_df_list['step_{}'.format(steps_n)] = error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mean_df = pd.DataFrame(\n",
    "      columns=['consist_0', 'consist_01', 'consist_03', 'consist_05', 'consist_1'])\n",
    "for key in error_df_list.keys():\n",
    "      error_mean_df.loc[key] = (np.sqrt(error_df_list[key])).mean()\n",
    "error_std_df = pd.DataFrame(\n",
    "      columns=['consist_0', 'consist_01', 'consist_03', 'consist_05', 'consist_1'])\n",
    "for key in error_df_list.keys():\n",
    "      error_std_df.loc[key] = (np.sqrt(error_df_list[key])).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consist_0</th>\n",
       "      <th>consist_01</th>\n",
       "      <th>consist_03</th>\n",
       "      <th>consist_05</th>\n",
       "      <th>consist_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step_100</th>\n",
       "      <td>1.700724</td>\n",
       "      <td>1.706189</td>\n",
       "      <td>1.478013</td>\n",
       "      <td>1.009715</td>\n",
       "      <td>1.695502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          consist_0  consist_01  consist_03  consist_05  consist_1\n",
       "step_100   1.700724    1.706189    1.478013    1.009715   1.695502"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range_mean: 6.3963081169128415 range_max: 6.994479179382324\n"
     ]
    }
   ],
   "source": [
    "range_list = []\n",
    "for i in range (n_test):\n",
    "      range_list.append((test_u[T*i:T*(i+1)].max() - test_u[T*i:T*(i+1)].min()).item())\n",
    "range_list = np.array(range_list)\n",
    "range_list_rep = range_list[:,None].repeat(6, axis=1)\n",
    "range_mean = range_list.mean()\n",
    "range_max = range_list.max()\n",
    "print('range_mean:', range_mean, 'range_max:', range_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mean_percent_df = 100*error_mean_df/range_mean.item()\n",
    "error_std_percent_df = 100*error_std_df/range_mean.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NRMSE in percentage (for 100 steps prediction) ablation results for model trained on different Gamma2 on measure invariant loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consist_0</th>\n",
       "      <th>consist_01</th>\n",
       "      <th>consist_03</th>\n",
       "      <th>consist_05</th>\n",
       "      <th>consist_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step_100</th>\n",
       "      <td>26.589153</td>\n",
       "      <td>26.674595</td>\n",
       "      <td>23.107285</td>\n",
       "      <td>15.785907</td>\n",
       "      <td>26.507506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          consist_0  consist_01  consist_03  consist_05  consist_1\n",
       "step_100  26.589153   26.674595   23.107285   15.785907  26.507506"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_mean_percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consist_0</th>\n",
       "      <th>consist_01</th>\n",
       "      <th>consist_03</th>\n",
       "      <th>consist_05</th>\n",
       "      <th>consist_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step_100</th>\n",
       "      <td>1.674041</td>\n",
       "      <td>1.739142</td>\n",
       "      <td>1.369389</td>\n",
       "      <td>1.766465</td>\n",
       "      <td>1.711914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          consist_0  consist_01  consist_03  consist_05  consist_1\n",
       "step_100   1.674041    1.739142    1.369389    1.766465   1.711914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_std_percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_operator_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
