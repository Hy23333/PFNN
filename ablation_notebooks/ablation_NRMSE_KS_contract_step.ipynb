{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ablation study on KS dataset for contraction length for training PFNN. \n",
    "A comparison of different trained PFNN on short-term predictions after contraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.utilities import *\n",
    "from model.koopman_base import *\n",
    "import sys\n",
    "sys.path.append('./model')\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import numpy.random as random\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "font = {'size'   : 12, 'family': 'Times New Roman'}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r1/v7355v5n0y3cw6l975b_dspm0000gn/T/ipykernel_21411/2715833728.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_tensor = torch.tensor(data_raw, dtype=torch.float)[...,::sub]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Main\n",
    "n_train = 1000\n",
    "n_test = 100\n",
    "\n",
    "sub = 4 # spatial subsample\n",
    "S = 512\n",
    "s = S//sub\n",
    "\n",
    "T_in = 500 # skip first 100 seconds of each trajectory to let trajectory reach attractor\n",
    "T = 200 # seconds to extract from each trajectory in data\n",
    "T_out = T_in + T\n",
    "step = 1 # Seconds to learn solution operator\n",
    "\n",
    "# Load data\n",
    "predloader = MatReader('../lake/data/KS.mat')\n",
    "data_raw = predloader.read_field('u')\n",
    "data_tensor = torch.tensor(data_raw, dtype=torch.float)[...,::sub]\n",
    "\n",
    "# randomly sample half episodes from the train data episodes\n",
    "episode_samples = int(0.5*n_train)\n",
    "data_sampled_train = data_tensor[torch.randperm(data_tensor[:n_train].size(0))[:episode_samples],:,:]\n",
    "# data_sampled_test = data_tensor[torch.randperm(data_tensor[-n_test:].size(0)),:,:]\n",
    "data_test = data_tensor[-n_test:,:,:]\n",
    "\n",
    "train_sample = data_sampled_train[:,T_in:T_out,:].reshape(-1, s)\n",
    "test_a = data_test[:,T_in-1:T_out-1,:].reshape(-1, s)\n",
    "test_u = data_test[:,T_in:T_out,:].reshape(-1, s)\n",
    "batch_size = 100\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "PFNN_step_100_path = 'fill_PFNN_C_lsi_1_model_path'\n",
    "model_step_100 = torch.load(PFNN_step_100_path, map_location=device)\n",
    "\n",
    "PFNN_step_300_path = 'fill_PFNN_C_lsi_3_model_path'\n",
    "model_step_300 = torch.load(PFNN_step_300_path, map_location=device)\n",
    "\n",
    "PFNN_step_500_path = 'fill_PFNN_C_lsi_5_model_path'\n",
    "model_step_500 = torch.load(PFNN_step_500_path, map_location=device)\n",
    "\n",
    "PFNN_step_700_path = 'fill_PFNN_C_lsi_7_model_path'\n",
    "model_step_700 = torch.load(PFNN_step_700_path, map_location=device)\n",
    "\n",
    "PFNN_step_900_path = 'fill_PFNN_C_lsi_9_model_path'\n",
    "model_step_900 = torch.load(PFNN_step_900_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating T steps of data\n",
    "def episode_l2_loss(pred, truth, n = 100):\n",
    "    return torch.mean((pred[:n] - truth[:n])**2)\n",
    "\n",
    "def episode_loss_collection(regressive_steps, loss_fn, test_u, pred_1, pred_2, pred_3, pred_4, pred_5):\n",
    "      loss_dict = {}\n",
    "\n",
    "      loss_step_100 = loss_fn(pred_1, test_u, n=regressive_steps)\n",
    "      loss_step_300 = loss_fn(pred_2, test_u, n=regressive_steps)\n",
    "      loss_step_500 = loss_fn(pred_3, test_u, n=regressive_steps)\n",
    "      loss_step_700 = loss_fn(pred_4, test_u, n=regressive_steps)\n",
    "      loss_step_900 = loss_fn(pred_5, test_u, n=regressive_steps)\n",
    "            \n",
    "      loss_dict['step_100'] = loss_step_100.item()\n",
    "      loss_dict['step_300'] = loss_step_300.item()\n",
    "      loss_dict['step_500'] = loss_step_500.item()\n",
    "      loss_dict['step_700'] = loss_step_700.item()\n",
    "      loss_dict['step_900'] = loss_step_900.item()\n",
    "\n",
    "      return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_n: 100 started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 17.25it/s]\n"
     ]
    }
   ],
   "source": [
    "steps_n_list = np.array([100])\n",
    "columns = ['step_100', 'step_300', 'step_500', 'step_700', 'step_900']\n",
    "error_df_list = {}\n",
    "for steps_n in steps_n_list:\n",
    "      print('steps_n:', steps_n, 'started.')\n",
    "      error_df = pd.DataFrame(columns=columns)\n",
    "      for init_id in tqdm(np.arange(n_test)):\n",
    "            step_100_long_pred = long_prediction(model_step_100, test_a, init_id, 1, s, s, T=steps_n)\n",
    "            step_300_long_pred = long_prediction(model_step_300, test_a, init_id, 1, s, s, T=steps_n)\n",
    "            step_500_long_pred = long_prediction(model_step_500, test_a, init_id, 1, s, s, T=steps_n)\n",
    "            step_700_long_pred = long_prediction(model_step_700, test_a, init_id, 1, s, s, T=steps_n)\n",
    "            step_900_long_pred = long_prediction(model_step_900, test_a, init_id, 1, s, s, T=steps_n)\n",
    "\n",
    "            episode_loss_dict = episode_loss_collection(steps_n, episode_l2_loss, test_u[int(init_id*T):], step_100_long_pred, step_300_long_pred, step_500_long_pred, step_700_long_pred, step_900_long_pred)\n",
    "            error_df.loc[init_id] = episode_loss_dict\n",
    "      error_df_list['step_{}'.format(steps_n)] = error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mean_df = pd.DataFrame(\n",
    "      columns=columns)\n",
    "for key in error_df_list.keys():\n",
    "      error_mean_df.loc[key] = (np.sqrt(error_df_list[key])).mean()\n",
    "error_std_df = pd.DataFrame(\n",
    "      columns=columns)\n",
    "for key in error_df_list.keys():\n",
    "      error_std_df.loc[key] = (np.sqrt(error_df_list[key])).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_100</th>\n",
       "      <th>step_300</th>\n",
       "      <th>step_500</th>\n",
       "      <th>step_700</th>\n",
       "      <th>step_900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step_100</th>\n",
       "      <td>37432.71029</td>\n",
       "      <td>2.991272</td>\n",
       "      <td>1.052192</td>\n",
       "      <td>0.963702</td>\n",
       "      <td>0.91051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             step_100  step_300  step_500  step_700  step_900\n",
       "step_100  37432.71029  2.991272  1.052192  0.963702   0.91051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range_mean: 6.3963081169128415 range_max: 6.994479179382324\n"
     ]
    }
   ],
   "source": [
    "range_list = []\n",
    "for i in range (n_test):\n",
    "      range_list.append((test_u[T*i:T*(i+1)].max() - test_u[T*i:T*(i+1)].min()).item())\n",
    "range_list = np.array(range_list)\n",
    "range_list_rep = range_list[:,None].repeat(6, axis=1)\n",
    "range_mean = range_list.mean()\n",
    "range_max = range_list.max()\n",
    "print('range_mean:', range_mean, 'range_max:', range_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_mean_percent_df = 100*error_mean_df/range_mean.item()\n",
    "error_std_percent_df = 100*error_std_df/range_mean.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NRMSE in percentage (for 100 steps prediction) ablation results for model trained on different length of relaxation time (steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_100</th>\n",
       "      <th>step_300</th>\n",
       "      <th>step_500</th>\n",
       "      <th>step_700</th>\n",
       "      <th>step_900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step_100</th>\n",
       "      <td>585223.688498</td>\n",
       "      <td>46.765596</td>\n",
       "      <td>16.449982</td>\n",
       "      <td>15.066542</td>\n",
       "      <td>14.234923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               step_100   step_300   step_500   step_700   step_900\n",
       "step_100  585223.688498  46.765596  16.449982  15.066542  14.234923"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_mean_percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_100</th>\n",
       "      <th>step_300</th>\n",
       "      <th>step_500</th>\n",
       "      <th>step_700</th>\n",
       "      <th>step_900</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step_100</th>\n",
       "      <td>1.910694e+06</td>\n",
       "      <td>12.980957</td>\n",
       "      <td>1.865617</td>\n",
       "      <td>2.228398</td>\n",
       "      <td>2.236051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              step_100   step_300  step_500  step_700  step_900\n",
       "step_100  1.910694e+06  12.980957  1.865617  2.228398  2.236051"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_std_percent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_operator_vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
